{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12344497-6579-4f38-93cd-441799151f8d",
   "metadata": {},
   "source": [
    "### Here we will explore an example of how to consolidate multiple csv files into a DataFrame and combined file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cec975-8187-4abf-bc3c-2e432a58fdae",
   "metadata": {},
   "source": [
    "https://data.census.gov/cedsci/table?q=Population%20Total&tid=PEPPOP2019.PEPANNRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d3b57f-1458-46cb-a4bb-74a1dbc4b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dae22cc-cacb-4dab-8ce6-59fb73bf3ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n",
      "2011\n"
     ]
    }
   ],
   "source": [
    "def get_year(path):\n",
    "    pattern = re.compile('Y([0-9]{4})')\n",
    "    year = re.search(pattern, path)\n",
    "    if year:\n",
    "        year = year[1]\n",
    "    return year\n",
    "\n",
    "path = \"ACSDP1Y2011.DP05_data_with_overlays_2021-11-20T222122.csv\"\n",
    "print(get_year(path))\n",
    "\n",
    "path = \"ACSDP1Y2011.DP05_metadata_2021-11-20T222122.csv\"\n",
    "print(get_year(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219c0696-e3a7-4176-9ee7-8c5cb5037698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "meta\n"
     ]
    }
   ],
   "source": [
    "def get_type(path):\n",
    "    meta = re.search('metadata', path)\n",
    "    if meta:\n",
    "        return 'meta'\n",
    "    else:\n",
    "        return 'data'\n",
    "\n",
    "path = \"ACSDP1Y2011.DP05_data_with_overlays_2021-11-20T222122.csv\"\n",
    "print(get_type(path))\n",
    "\n",
    "path = \"ACSDP1Y2011.DP05_metadata_2021-11-20T222122.csv\"\n",
    "print(get_type(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24860deb-febc-430c-a64a-51f2b3b27b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2011', 'data')\n",
      "('2011', 'meta')\n"
     ]
    }
   ],
   "source": [
    "def get_year_type(path):\n",
    "    return get_year(path),get_type(path)\n",
    "\n",
    "path = \"ACSDP1Y2011.DP05_data_with_overlays_2021-11-20T222122.csv\"\n",
    "print(get_year_type(path))\n",
    "\n",
    "path = \"ACSDP1Y2011.DP05_metadata_2021-11-20T222122.csv\"\n",
    "print(get_year_type(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21a0fc53-d3c3-4148-a336-b5c122028c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_meta(df):\n",
    "    df.columns = ['id', 'name']\n",
    "    \n",
    "    # expand the names into their own columns\n",
    "    df = df[['id']].merge(df['name'].str.split('!!').apply(pd.Series), left_index = True, right_index = True)\n",
    "    df.columns = ['id'] + ['level_{}'.format(x) for x in range(len(df.columns) - 1)]\n",
    "    \n",
    "    # keep only what I care about\n",
    "    df = df.loc[df['level_0'].str.lower() == 'estimate']\n",
    "    \n",
    "    # set the corresponding index and drop id\n",
    "    df.index = df['id']\n",
    "    df = df.drop(columns = ['id'])\n",
    "    \n",
    "    return(df.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d591f93-37d8-4330-9d1a-c46621d7a80f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7c49fa-8039-443a-a9be-49986c2d696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data(df, year):\n",
    "    # slice it based on the last observation\n",
    "    df = df.iloc[-1]\n",
    "    \n",
    "    # create a multi-index level including the year. We need to create a list of tupples. \n",
    "    \n",
    "    # option 1\n",
    "    tuples = [(year, ind) for ind in df.index]\n",
    "    \n",
    "    # option 2\n",
    "    tuples = list(zip(*[[year]*len(df), df.index]))\n",
    "    index = pd.MultiIndex.from_tuples(tuples, names=[\"year\", \"name\"])\n",
    "    \n",
    "    # assign the new index\n",
    "    df.index = index\n",
    "    \n",
    "    # and just for clarity, let's name this\n",
    "    df.name = 'data'\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9cc54-cdd7-45d2-b5a1-17cd8b0ac419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f281c02-3b10-4a88-ad54-0187ccbfe593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_file(meta, *args):\n",
    "    if meta == 'meta':\n",
    "        return(fix_meta(*args))\n",
    "    else:\n",
    "        return(fix_data(*args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bedd556-7aa5-466e-8bd6-1ecc1df5b41c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010  |  data  |  .\\population_growth\\ACSDP1Y2010.DP05_data_with_overlays_2021-11-20T222122.csv\n",
      "2010  |  meta  |  .\\population_growth\\ACSDP1Y2010.DP05_metadata_2021-11-20T222122.csv\n",
      "2010  |  data  |  .\\population_growth\\ACSDP1Y2010.DP05_table_title_2021-11-20T222122.txt\n",
      "2011  |  data  |  .\\population_growth\\ACSDP1Y2011.DP05_data_with_overlays_2021-11-20T222122.csv\n",
      "2011  |  meta  |  .\\population_growth\\ACSDP1Y2011.DP05_metadata_2021-11-20T222122.csv\n",
      "2011  |  data  |  .\\population_growth\\ACSDP1Y2011.DP05_table_title_2021-11-20T222122.txt\n",
      "2012  |  data  |  .\\population_growth\\ACSDP1Y2012.DP05_data_with_overlays_2021-11-20T222122.csv\n",
      "2012  |  meta  |  .\\population_growth\\ACSDP1Y2012.DP05_metadata_2021-11-20T222122.csv\n",
      "2012  |  data  |  .\\population_growth\\ACSDP1Y2012.DP05_table_title_2021-11-20T222122.txt\n",
      "2013  |  data  |  .\\population_growth\\ACSDP1Y2013.DP05_data_with_overlays_2021-11-20T222122.csv\n",
      "2013  |  meta  |  .\\population_growth\\ACSDP1Y2013.DP05_metadata_2021-11-20T222122.csv\n",
      "2013  |  data  |  .\\population_growth\\ACSDP1Y2013.DP05_table_title_2021-11-20T222122.txt\n",
      "2014  |  data  |  .\\population_growth\\ACSDP1Y2014.DP05_data_with_overlays_2021-11-20T222122.csv\n",
      "2014  |  meta  |  .\\population_growth\\ACSDP1Y2014.DP05_metadata_2021-11-20T222122.csv\n",
      "2014  |  data  |  .\\population_growth\\ACSDP1Y2014.DP05_table_title_2021-11-20T222122.txt\n",
      "2015  |  data  |  .\\population_growth\\ACSDP1Y2015.DP05_data_with_overlays_2021-11-20T222122.csv\n",
      "2015  |  meta  |  .\\population_growth\\ACSDP1Y2015.DP05_metadata_2021-11-20T222122.csv\n",
      "2015  |  data  |  .\\population_growth\\ACSDP1Y2015.DP05_table_title_2021-11-20T222122.txt\n",
      "2016  |  data  |  .\\population_growth\\ACSDP1Y2016.DP05_data_with_overlays_2021-11-20T222122.csv\n",
      "2016  |  meta  |  .\\population_growth\\ACSDP1Y2016.DP05_metadata_2021-11-20T222122.csv\n",
      "2016  |  data  |  .\\population_growth\\ACSDP1Y2016.DP05_table_title_2021-11-20T222122.txt\n",
      "2017  |  data  |  .\\population_growth\\ACSDP1Y2017.DP05_data_with_overlays_2021-11-20T222122.csv\n",
      "2017  |  meta  |  .\\population_growth\\ACSDP1Y2017.DP05_metadata_2021-11-20T222122.csv\n",
      "2017  |  data  |  .\\population_growth\\ACSDP1Y2017.DP05_table_title_2021-11-20T222122.txt\n",
      "2018  |  data  |  .\\population_growth\\ACSDP1Y2018.DP05_data_with_overlays_2021-11-20T222122.csv\n",
      "2018  |  meta  |  .\\population_growth\\ACSDP1Y2018.DP05_metadata_2021-11-20T222122.csv\n",
      "2018  |  data  |  .\\population_growth\\ACSDP1Y2018.DP05_table_title_2021-11-20T222122.txt\n",
      "2019  |  data  |  .\\population_growth\\ACSDP1Y2019.DP05_data_with_overlays_2021-11-20T222122.csv\n",
      "2019  |  meta  |  .\\population_growth\\ACSDP1Y2019.DP05_metadata_2021-11-20T222122.csv\n",
      "2019  |  data  |  .\\population_growth\\ACSDP1Y2019.DP05_table_title_2021-11-20T222122.txt\n"
     ]
    }
   ],
   "source": [
    "path = '.\\population_growth/*'\n",
    "for file_path in glob.glob(path):\n",
    "    year, meta = get_year_type(file_path)\n",
    "    print(year,' | ', meta,' | ', file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36cee335-af2e-46d7-a293-f75656959a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2010': {'Hello': None, 'World': None},\n",
       " '2011': {'Bye': None},\n",
       " '2024': {'Welcome': '6191', 'Bye': '1700', 'FRE': None, 'class': None}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = ['2010Hello','2010World','2011Bye','2024Welcome6191','2024Bye1700','2024FRE','2024class']\n",
    "my_dict = {}\n",
    "\n",
    "pattern = re.compile('([0-9]{4})([A-z]+)([0-9]{4})?')\n",
    "\n",
    "for i in my_list:\n",
    "    year = re.search(pattern, i)[1]\n",
    "    word = re.search(pattern, i)[2]\n",
    "    number = re.search(pattern, i)[3]\n",
    "    if year in my_dict:\n",
    "        my_dict[year][word] = number\n",
    "    else:\n",
    "        my_dict[year] = {word:number}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e824b32-a607-4dfd-9291-1b810059c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that we are ignoring the .txt files\n",
    "path = '.\\population_growth\\*.csv'\n",
    "\n",
    "# I want to create a dictionary that keeps the years as keys and the meta/data as elements\n",
    "years = {}\n",
    "\n",
    "for file_path in glob.glob(path):\n",
    "    year, meta = get_year_type(file_path)\n",
    "    \n",
    "    if year in years:\n",
    "        years[year][meta] = fix_file(meta, pd.read_csv(file_path))\n",
    "    else:\n",
    "        # the structure needs to be created\n",
    "        years[year] = {meta: fix_file(meta, pd.read_csv(file_path), year)}\n",
    "# years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b16f4e8-9b4b-4dbf-8cd4-fccd1ce76ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4476913a-8254-42d1-b3a4-21e9fb271528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'meta'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years['2010'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb834e-a072-45bb-9dfd-3e35069b7478",
   "metadata": {},
   "source": [
    "I want to make it so that the output of this script are 2 files: a data file and a meta file so that they can be used later\n",
    "\n",
    "I want to then consolidate all the metas and all the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea32260-c376-493e-9c9b-25324ab92616",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame()\n",
    "data = pd.Series(index = pd.MultiIndex.from_tuples((), names=[\"year\", \"name\"]), name = 'data')\n",
    "\n",
    "for k, v in years.items():\n",
    "    meta = pd.concat([meta, v['meta']])\n",
    "    data = pd.concat([data, v['data']])\n",
    "\n",
    "# final touches before exporting\n",
    "meta = meta.drop_duplicates()\n",
    "meta.index = meta.pop('id')\n",
    "data = data.loc[:, meta.index]\n",
    "\n",
    "meta.to_csv('.\\data\\metadata2.csv')\n",
    "data.to_csv('.\\data\\data2.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
